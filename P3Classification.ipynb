{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alejandro Figueroa Ram√≠rez\n",
    "Project 3 CIIC 5015 \n",
    "841-17-2484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "lr = 0.01 \n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.7,), (0.7,)),])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print images using MatPlotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape:  (3, 122, 242)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seven zero  nine  five  eight seven zero  one   six   one   seven six   four  four  seven five  four  seven nine  eight four  four  one   six   one   nine  five  seven seven six   three four \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    print(\"img shape: \", npimg.shape)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random images\n",
    "detaiter = iter(trainloader)\n",
    "images, labels = next(detaiter)\n",
    "\n",
    "# Show images \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Network Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN1(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (relu1): ReLU()\n",
      "  (flatten1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=12544, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 4 layer CNN model\n",
    "class CNN1(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        # 1 input image channel, 10 output channels, 5x5 convolutional filters\n",
    "        super(CNN1,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, padding='same')\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(12544, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.flatten1(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "cmodel = CNN1(28*28)\n",
    "print(cmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CNN1                                     [32, 1, 28, 28]           [32, 10]                  --\n",
       "‚îú‚îÄConv2d: 1-1                            [32, 1, 28, 28]           [32, 16, 28, 28]          416\n",
       "‚îú‚îÄReLU: 1-2                              [32, 16, 28, 28]          [32, 16, 28, 28]          --\n",
       "‚îú‚îÄFlatten: 1-3                           [32, 16, 28, 28]          [32, 12544]               --\n",
       "‚îú‚îÄLinear: 1-4                            [32, 12544]               [32, 10]                  125,450\n",
       "===================================================================================================================\n",
       "Total params: 125,866\n",
       "Trainable params: 125,866\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 14.45\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 3.21\n",
       "Params size (MB): 0.50\n",
       "Estimated Total Size (MB): 3.82\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 32 #for illustration\n",
    "\n",
    "summary(cmodel, input_size=(batch_size, 1, 28, 28), device='cpu', col_names=['input_size', 'output_size',\n",
    "                                                                        'num_params'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cmodel.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "--------------\n",
      "loss: 2.365680  [    0/60000]\n",
      "loss: 0.844029  [ 3200/60000]\n",
      "loss: 0.488173  [ 6400/60000]\n",
      "loss: 0.300481  [ 9600/60000]\n",
      "loss: 0.861630  [12800/60000]\n",
      "loss: 0.442720  [16000/60000]\n",
      "loss: 0.417923  [19200/60000]\n",
      "loss: 0.348485  [22400/60000]\n",
      "loss: 0.325033  [25600/60000]\n",
      "loss: 0.105820  [28800/60000]\n",
      "loss: 0.168044  [32000/60000]\n",
      "loss: 0.173273  [35200/60000]\n",
      "loss: 0.280705  [38400/60000]\n",
      "loss: 0.374290  [41600/60000]\n",
      "loss: 0.293421  [44800/60000]\n",
      "loss: 0.285845  [48000/60000]\n",
      "loss: 0.179378  [51200/60000]\n",
      "loss: 0.160264  [54400/60000]\n",
      "loss: 0.059884  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.165102 \n",
      "\n",
      "Epoch:  1\n",
      "--------------\n",
      "loss: 0.179960  [    0/60000]\n",
      "loss: 0.196189  [ 3200/60000]\n",
      "loss: 0.085982  [ 6400/60000]\n",
      "loss: 0.711039  [ 9600/60000]\n",
      "loss: 0.056294  [12800/60000]\n",
      "loss: 0.047444  [16000/60000]\n",
      "loss: 0.149061  [19200/60000]\n",
      "loss: 0.182653  [22400/60000]\n",
      "loss: 0.209194  [25600/60000]\n",
      "loss: 0.177781  [28800/60000]\n",
      "loss: 0.065535  [32000/60000]\n",
      "loss: 0.043714  [35200/60000]\n",
      "loss: 0.192900  [38400/60000]\n",
      "loss: 0.090927  [41600/60000]\n",
      "loss: 0.164997  [44800/60000]\n",
      "loss: 0.169176  [48000/60000]\n",
      "loss: 0.086616  [51200/60000]\n",
      "loss: 0.290125  [54400/60000]\n",
      "loss: 0.340180  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.109908 \n",
      "\n",
      "Epoch:  2\n",
      "--------------\n",
      "loss: 0.162047  [    0/60000]\n",
      "loss: 0.016869  [ 3200/60000]\n",
      "loss: 0.284063  [ 6400/60000]\n",
      "loss: 0.288520  [ 9600/60000]\n",
      "loss: 0.060068  [12800/60000]\n",
      "loss: 0.137493  [16000/60000]\n",
      "loss: 0.086808  [19200/60000]\n",
      "loss: 0.507967  [22400/60000]\n",
      "loss: 0.165918  [25600/60000]\n",
      "loss: 0.042661  [28800/60000]\n",
      "loss: 0.099294  [32000/60000]\n",
      "loss: 0.027489  [35200/60000]\n",
      "loss: 0.026158  [38400/60000]\n",
      "loss: 0.046375  [41600/60000]\n",
      "loss: 0.265845  [44800/60000]\n",
      "loss: 0.051306  [48000/60000]\n",
      "loss: 0.135812  [51200/60000]\n",
      "loss: 0.067172  [54400/60000]\n",
      "loss: 0.172547  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.092723 \n",
      "\n",
      "Epoch:  3\n",
      "--------------\n",
      "loss: 0.020352  [    0/60000]\n",
      "loss: 0.209852  [ 3200/60000]\n",
      "loss: 0.019930  [ 6400/60000]\n",
      "loss: 0.065397  [ 9600/60000]\n",
      "loss: 0.062931  [12800/60000]\n",
      "loss: 0.132263  [16000/60000]\n",
      "loss: 0.094556  [19200/60000]\n",
      "loss: 0.046899  [22400/60000]\n",
      "loss: 0.062830  [25600/60000]\n",
      "loss: 0.049909  [28800/60000]\n",
      "loss: 0.124998  [32000/60000]\n",
      "loss: 0.044550  [35200/60000]\n",
      "loss: 0.371646  [38400/60000]\n",
      "loss: 0.061431  [41600/60000]\n",
      "loss: 0.121965  [44800/60000]\n",
      "loss: 0.051579  [48000/60000]\n",
      "loss: 0.027787  [51200/60000]\n",
      "loss: 0.130700  [54400/60000]\n",
      "loss: 0.029424  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.078502 \n",
      "\n",
      "Epoch:  4\n",
      "--------------\n",
      "loss: 0.027375  [    0/60000]\n",
      "loss: 0.039099  [ 3200/60000]\n",
      "loss: 0.185294  [ 6400/60000]\n",
      "loss: 0.017203  [ 9600/60000]\n",
      "loss: 0.008628  [12800/60000]\n",
      "loss: 0.014317  [16000/60000]\n",
      "loss: 0.233715  [19200/60000]\n",
      "loss: 0.036013  [22400/60000]\n",
      "loss: 0.113988  [25600/60000]\n",
      "loss: 0.163015  [28800/60000]\n",
      "loss: 0.217951  [32000/60000]\n",
      "loss: 0.006516  [35200/60000]\n",
      "loss: 0.047976  [38400/60000]\n",
      "loss: 0.021454  [41600/60000]\n",
      "loss: 0.025869  [44800/60000]\n",
      "loss: 0.022654  [48000/60000]\n",
      "loss: 0.058171  [51200/60000]\n",
      "loss: 0.036933  [54400/60000]\n",
      "loss: 0.035559  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.078578 \n",
      "\n",
      "Epoch:  5\n",
      "--------------\n",
      "loss: 0.056577  [    0/60000]\n",
      "loss: 0.234742  [ 3200/60000]\n",
      "loss: 0.153541  [ 6400/60000]\n",
      "loss: 0.037440  [ 9600/60000]\n",
      "loss: 0.032069  [12800/60000]\n",
      "loss: 0.058490  [16000/60000]\n",
      "loss: 0.041526  [19200/60000]\n",
      "loss: 0.130865  [22400/60000]\n",
      "loss: 0.034648  [25600/60000]\n",
      "loss: 0.072300  [28800/60000]\n",
      "loss: 0.012128  [32000/60000]\n",
      "loss: 0.009975  [35200/60000]\n",
      "loss: 0.008173  [38400/60000]\n",
      "loss: 0.153139  [41600/60000]\n",
      "loss: 0.111361  [44800/60000]\n",
      "loss: 0.016709  [48000/60000]\n",
      "loss: 0.019759  [51200/60000]\n",
      "loss: 0.089499  [54400/60000]\n",
      "loss: 0.039682  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.069592 \n",
      "\n",
      "Epoch:  6\n",
      "--------------\n",
      "loss: 0.015263  [    0/60000]\n",
      "loss: 0.202590  [ 3200/60000]\n",
      "loss: 0.154403  [ 6400/60000]\n",
      "loss: 0.135576  [ 9600/60000]\n",
      "loss: 0.019841  [12800/60000]\n",
      "loss: 0.027975  [16000/60000]\n",
      "loss: 0.015435  [19200/60000]\n",
      "loss: 0.005155  [22400/60000]\n",
      "loss: 0.058783  [25600/60000]\n",
      "loss: 0.060768  [28800/60000]\n",
      "loss: 0.008962  [32000/60000]\n",
      "loss: 0.019625  [35200/60000]\n",
      "loss: 0.130968  [38400/60000]\n",
      "loss: 0.120763  [41600/60000]\n",
      "loss: 0.070334  [44800/60000]\n",
      "loss: 0.080251  [48000/60000]\n",
      "loss: 0.022053  [51200/60000]\n",
      "loss: 0.247737  [54400/60000]\n",
      "loss: 0.175648  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.062655 \n",
      "\n",
      "Epoch:  7\n",
      "--------------\n",
      "loss: 0.006319  [    0/60000]\n",
      "loss: 0.097027  [ 3200/60000]\n",
      "loss: 0.025341  [ 6400/60000]\n",
      "loss: 0.032919  [ 9600/60000]\n",
      "loss: 0.021875  [12800/60000]\n",
      "loss: 0.020717  [16000/60000]\n",
      "loss: 0.053098  [19200/60000]\n",
      "loss: 0.035349  [22400/60000]\n",
      "loss: 0.015981  [25600/60000]\n",
      "loss: 0.055192  [28800/60000]\n",
      "loss: 0.138672  [32000/60000]\n",
      "loss: 0.139333  [35200/60000]\n",
      "loss: 0.025342  [38400/60000]\n",
      "loss: 0.060829  [41600/60000]\n",
      "loss: 0.023244  [44800/60000]\n",
      "loss: 0.145015  [48000/60000]\n",
      "loss: 0.005307  [51200/60000]\n",
      "loss: 0.072481  [54400/60000]\n",
      "loss: 0.012304  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.061950 \n",
      "\n",
      "Epoch:  8\n",
      "--------------\n",
      "loss: 0.060434  [    0/60000]\n",
      "loss: 0.012254  [ 3200/60000]\n",
      "loss: 0.038599  [ 6400/60000]\n",
      "loss: 0.100464  [ 9600/60000]\n",
      "loss: 0.006774  [12800/60000]\n",
      "loss: 0.008803  [16000/60000]\n",
      "loss: 0.035353  [19200/60000]\n",
      "loss: 0.021899  [22400/60000]\n",
      "loss: 0.010641  [25600/60000]\n",
      "loss: 0.190818  [28800/60000]\n",
      "loss: 0.065306  [32000/60000]\n",
      "loss: 0.096926  [35200/60000]\n",
      "loss: 0.165708  [38400/60000]\n",
      "loss: 0.038597  [41600/60000]\n",
      "loss: 0.062864  [44800/60000]\n",
      "loss: 0.016304  [48000/60000]\n",
      "loss: 0.023087  [51200/60000]\n",
      "loss: 0.059052  [54400/60000]\n",
      "loss: 0.033718  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.056154 \n",
      "\n",
      "Epoch:  9\n",
      "--------------\n",
      "loss: 0.005107  [    0/60000]\n",
      "loss: 0.040305  [ 3200/60000]\n",
      "loss: 0.019205  [ 6400/60000]\n",
      "loss: 0.023136  [ 9600/60000]\n",
      "loss: 0.022341  [12800/60000]\n",
      "loss: 0.017745  [16000/60000]\n",
      "loss: 0.009619  [19200/60000]\n",
      "loss: 0.172075  [22400/60000]\n",
      "loss: 0.015979  [25600/60000]\n",
      "loss: 0.018766  [28800/60000]\n",
      "loss: 0.036416  [32000/60000]\n",
      "loss: 0.017491  [35200/60000]\n",
      "loss: 0.081465  [38400/60000]\n",
      "loss: 0.075162  [41600/60000]\n",
      "loss: 0.039952  [44800/60000]\n",
      "loss: 0.050187  [48000/60000]\n",
      "loss: 0.045965  [51200/60000]\n",
      "loss: 0.045915  [54400/60000]\n",
      "loss: 0.008018  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.051425 \n",
      "\n",
      "Epoch:  10\n",
      "--------------\n",
      "loss: 0.066248  [    0/60000]\n",
      "loss: 0.035644  [ 3200/60000]\n",
      "loss: 0.028321  [ 6400/60000]\n",
      "loss: 0.034518  [ 9600/60000]\n",
      "loss: 0.035255  [12800/60000]\n",
      "loss: 0.032128  [16000/60000]\n",
      "loss: 0.076187  [19200/60000]\n",
      "loss: 0.017527  [22400/60000]\n",
      "loss: 0.014186  [25600/60000]\n",
      "loss: 0.010048  [28800/60000]\n",
      "loss: 0.008209  [32000/60000]\n",
      "loss: 0.023691  [35200/60000]\n",
      "loss: 0.016582  [38400/60000]\n",
      "loss: 0.038567  [41600/60000]\n",
      "loss: 0.012099  [44800/60000]\n",
      "loss: 0.010236  [48000/60000]\n",
      "loss: 0.113712  [51200/60000]\n",
      "loss: 0.025433  [54400/60000]\n",
      "loss: 0.171563  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.061739 \n",
      "\n",
      "Epoch:  11\n",
      "--------------\n",
      "loss: 0.027378  [    0/60000]\n",
      "loss: 0.033367  [ 3200/60000]\n",
      "loss: 0.021571  [ 6400/60000]\n",
      "loss: 0.030920  [ 9600/60000]\n",
      "loss: 0.014821  [12800/60000]\n",
      "loss: 0.018662  [16000/60000]\n",
      "loss: 0.008552  [19200/60000]\n",
      "loss: 0.043400  [22400/60000]\n",
      "loss: 0.014300  [25600/60000]\n",
      "loss: 0.077487  [28800/60000]\n",
      "loss: 0.002423  [32000/60000]\n",
      "loss: 0.057369  [35200/60000]\n",
      "loss: 0.004575  [38400/60000]\n",
      "loss: 0.099537  [41600/60000]\n",
      "loss: 0.021481  [44800/60000]\n",
      "loss: 0.005870  [48000/60000]\n",
      "loss: 0.055730  [51200/60000]\n",
      "loss: 0.035549  [54400/60000]\n",
      "loss: 0.003162  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.058341 \n",
      "\n",
      "Epoch:  12\n",
      "--------------\n",
      "loss: 0.144438  [    0/60000]\n",
      "loss: 0.008523  [ 3200/60000]\n",
      "loss: 0.101246  [ 6400/60000]\n",
      "loss: 0.017262  [ 9600/60000]\n",
      "loss: 0.024603  [12800/60000]\n",
      "loss: 0.064442  [16000/60000]\n",
      "loss: 0.033018  [19200/60000]\n",
      "loss: 0.027993  [22400/60000]\n",
      "loss: 0.007291  [25600/60000]\n",
      "loss: 0.032112  [28800/60000]\n",
      "loss: 0.022712  [32000/60000]\n",
      "loss: 0.123091  [35200/60000]\n",
      "loss: 0.024038  [38400/60000]\n",
      "loss: 0.024725  [41600/60000]\n",
      "loss: 0.047983  [44800/60000]\n",
      "loss: 0.108003  [48000/60000]\n",
      "loss: 0.011547  [51200/60000]\n",
      "loss: 0.017319  [54400/60000]\n",
      "loss: 0.041046  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.050898 \n",
      "\n",
      "Epoch:  13\n",
      "--------------\n",
      "loss: 0.016726  [    0/60000]\n",
      "loss: 0.013161  [ 3200/60000]\n",
      "loss: 0.022220  [ 6400/60000]\n",
      "loss: 0.013057  [ 9600/60000]\n",
      "loss: 0.051929  [12800/60000]\n",
      "loss: 0.014669  [16000/60000]\n",
      "loss: 0.049645  [19200/60000]\n",
      "loss: 0.135840  [22400/60000]\n",
      "loss: 0.143304  [25600/60000]\n",
      "loss: 0.027096  [28800/60000]\n",
      "loss: 0.018486  [32000/60000]\n",
      "loss: 0.052957  [35200/60000]\n",
      "loss: 0.085652  [38400/60000]\n",
      "loss: 0.357722  [41600/60000]\n",
      "loss: 0.042080  [44800/60000]\n",
      "loss: 0.003060  [48000/60000]\n",
      "loss: 0.028902  [51200/60000]\n",
      "loss: 0.001703  [54400/60000]\n",
      "loss: 0.028836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.051626 \n",
      "\n",
      "Epoch:  14\n",
      "--------------\n",
      "loss: 0.031372  [    0/60000]\n",
      "loss: 0.002371  [ 3200/60000]\n",
      "loss: 0.032015  [ 6400/60000]\n",
      "loss: 0.249425  [ 9600/60000]\n",
      "loss: 0.071153  [12800/60000]\n",
      "loss: 0.052001  [16000/60000]\n",
      "loss: 0.016794  [19200/60000]\n",
      "loss: 0.013551  [22400/60000]\n",
      "loss: 0.065760  [25600/60000]\n",
      "loss: 0.017797  [28800/60000]\n",
      "loss: 0.033786  [32000/60000]\n",
      "loss: 0.022159  [35200/60000]\n",
      "loss: 0.069091  [38400/60000]\n",
      "loss: 0.001273  [41600/60000]\n",
      "loss: 0.021163  [44800/60000]\n",
      "loss: 0.009133  [48000/60000]\n",
      "loss: 0.010849  [51200/60000]\n",
      "loss: 0.017566  [54400/60000]\n",
      "loss: 0.022542  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.056938 \n",
      "\n",
      "Epoch:  15\n",
      "--------------\n",
      "loss: 0.013543  [    0/60000]\n",
      "loss: 0.034954  [ 3200/60000]\n",
      "loss: 0.003964  [ 6400/60000]\n",
      "loss: 0.017201  [ 9600/60000]\n",
      "loss: 0.014213  [12800/60000]\n",
      "loss: 0.012304  [16000/60000]\n",
      "loss: 0.089827  [19200/60000]\n",
      "loss: 0.009284  [22400/60000]\n",
      "loss: 0.081176  [25600/60000]\n",
      "loss: 0.032449  [28800/60000]\n",
      "loss: 0.008690  [32000/60000]\n",
      "loss: 0.006498  [35200/60000]\n",
      "loss: 0.028893  [38400/60000]\n",
      "loss: 0.014906  [41600/60000]\n",
      "loss: 0.019549  [44800/60000]\n",
      "loss: 0.032358  [48000/60000]\n",
      "loss: 0.019247  [51200/60000]\n",
      "loss: 0.005103  [54400/60000]\n",
      "loss: 0.008953  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.053671 \n",
      "\n",
      "Epoch:  16\n",
      "--------------\n",
      "loss: 0.144297  [    0/60000]\n",
      "loss: 0.029141  [ 3200/60000]\n",
      "loss: 0.082875  [ 6400/60000]\n",
      "loss: 0.045593  [ 9600/60000]\n",
      "loss: 0.001500  [12800/60000]\n",
      "loss: 0.051105  [16000/60000]\n",
      "loss: 0.043666  [19200/60000]\n",
      "loss: 0.020426  [22400/60000]\n",
      "loss: 0.006335  [25600/60000]\n",
      "loss: 0.021563  [28800/60000]\n",
      "loss: 0.040977  [32000/60000]\n",
      "loss: 0.059091  [35200/60000]\n",
      "loss: 0.037223  [38400/60000]\n",
      "loss: 0.002493  [41600/60000]\n",
      "loss: 0.055869  [44800/60000]\n",
      "loss: 0.014930  [48000/60000]\n",
      "loss: 0.019769  [51200/60000]\n",
      "loss: 0.011469  [54400/60000]\n",
      "loss: 0.004274  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.051669 \n",
      "\n",
      "Epoch:  17\n",
      "--------------\n",
      "loss: 0.123474  [    0/60000]\n",
      "loss: 0.014898  [ 3200/60000]\n",
      "loss: 0.011785  [ 6400/60000]\n",
      "loss: 0.121494  [ 9600/60000]\n",
      "loss: 0.014775  [12800/60000]\n",
      "loss: 0.028914  [16000/60000]\n",
      "loss: 0.003050  [19200/60000]\n",
      "loss: 0.045809  [22400/60000]\n",
      "loss: 0.002313  [25600/60000]\n",
      "loss: 0.081254  [28800/60000]\n",
      "loss: 0.001057  [32000/60000]\n",
      "loss: 0.014885  [35200/60000]\n",
      "loss: 0.012641  [38400/60000]\n",
      "loss: 0.011109  [41600/60000]\n",
      "loss: 0.005406  [44800/60000]\n",
      "loss: 0.075499  [48000/60000]\n",
      "loss: 0.107648  [51200/60000]\n",
      "loss: 0.000862  [54400/60000]\n",
      "loss: 0.037919  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.052557 \n",
      "\n",
      "Epoch:  18\n",
      "--------------\n",
      "loss: 0.047947  [    0/60000]\n",
      "loss: 0.097677  [ 3200/60000]\n",
      "loss: 0.001839  [ 6400/60000]\n",
      "loss: 0.008709  [ 9600/60000]\n",
      "loss: 0.021617  [12800/60000]\n",
      "loss: 0.008510  [16000/60000]\n",
      "loss: 0.001512  [19200/60000]\n",
      "loss: 0.004285  [22400/60000]\n",
      "loss: 0.027221  [25600/60000]\n",
      "loss: 0.333023  [28800/60000]\n",
      "loss: 0.141315  [32000/60000]\n",
      "loss: 0.001751  [35200/60000]\n",
      "loss: 0.007284  [38400/60000]\n",
      "loss: 0.017453  [41600/60000]\n",
      "loss: 0.001273  [44800/60000]\n",
      "loss: 0.071728  [48000/60000]\n",
      "loss: 0.040510  [51200/60000]\n",
      "loss: 0.010294  [54400/60000]\n",
      "loss: 0.001519  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.053939 \n",
      "\n",
      "Epoch:  19\n",
      "--------------\n",
      "loss: 0.017453  [    0/60000]\n",
      "loss: 0.024583  [ 3200/60000]\n",
      "loss: 0.133119  [ 6400/60000]\n",
      "loss: 0.022861  [ 9600/60000]\n",
      "loss: 0.034569  [12800/60000]\n",
      "loss: 0.003271  [16000/60000]\n",
      "loss: 0.165609  [19200/60000]\n",
      "loss: 0.023384  [22400/60000]\n",
      "loss: 0.060928  [25600/60000]\n",
      "loss: 0.002821  [28800/60000]\n",
      "loss: 0.000455  [32000/60000]\n",
      "loss: 0.107875  [35200/60000]\n",
      "loss: 0.017984  [38400/60000]\n",
      "loss: 0.009436  [41600/60000]\n",
      "loss: 0.002246  [44800/60000]\n",
      "loss: 0.040556  [48000/60000]\n",
      "loss: 0.001940  [51200/60000]\n",
      "loss: 0.031803  [54400/60000]\n",
      "loss: 0.017082  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.052480 \n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print(\"Epoch: \", epoch)\n",
    "    print(\"--------------\") \n",
    "\n",
    "    running_loss = 0.0\n",
    "    size = len(trainloader.dataset)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cmodel(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(inputs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    size = len(testloader.dataset)\n",
    "    num_batches = len(testloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            #X = X.to(device)\n",
    "            #y = y.to(device)\n",
    "            pred = cmodel(X)\n",
    "            test_loss += criterion(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = cmodel(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN2(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (relu2): ReLU()\n",
      "  (flatten1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=12544, out_features=84, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 8 layer CNN model\n",
    "class CNN2(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN2,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding='same')\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding='same')\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(12544, 84)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.flatten1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "cmodel2 = CNN2(28*28)\n",
    "optimizer = torch.optim.SGD(cmodel2.parameters(), lr = lr)\n",
    "print(cmodel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CNN2                                     [32, 1, 28, 28]           [32, 10]                  --\n",
       "‚îú‚îÄConv2d: 1-1                            [32, 1, 28, 28]           [32, 6, 28, 28]           156\n",
       "‚îú‚îÄReLU: 1-2                              [32, 6, 28, 28]           [32, 6, 28, 28]           --\n",
       "‚îú‚îÄConv2d: 1-3                            [32, 6, 28, 28]           [32, 16, 28, 28]          2,416\n",
       "‚îú‚îÄReLU: 1-4                              [32, 16, 28, 28]          [32, 16, 28, 28]          --\n",
       "‚îú‚îÄFlatten: 1-5                           [32, 16, 28, 28]          [32, 12544]               --\n",
       "‚îú‚îÄLinear: 1-6                            [32, 12544]               [32, 84]                  1,053,780\n",
       "‚îú‚îÄReLU: 1-7                              [32, 84]                  [32, 84]                  --\n",
       "‚îú‚îÄLinear: 1-8                            [32, 84]                  [32, 10]                  850\n",
       "===================================================================================================================\n",
       "Total params: 1,057,202\n",
       "Trainable params: 1,057,202\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 98.27\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 4.44\n",
       "Params size (MB): 4.23\n",
       "Estimated Total Size (MB): 8.77\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 32 #for illustration\n",
    "\n",
    "summary(cmodel2, input_size=(batch_size, 1, 28, 28), device='cpu', col_names=['input_size', 'output_size',\n",
    "                                                                        'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "--------------\n",
      "loss: 2.305481  [    0/60000]\n",
      "loss: 1.531955  [ 3200/60000]\n",
      "loss: 0.687858  [ 6400/60000]\n",
      "loss: 0.753323  [ 9600/60000]\n",
      "loss: 0.546061  [12800/60000]\n",
      "loss: 0.264103  [16000/60000]\n",
      "loss: 0.263197  [19200/60000]\n",
      "loss: 0.201854  [22400/60000]\n",
      "loss: 0.374222  [25600/60000]\n",
      "loss: 0.372647  [28800/60000]\n",
      "loss: 0.083319  [32000/60000]\n",
      "loss: 0.116209  [35200/60000]\n",
      "loss: 0.491240  [38400/60000]\n",
      "loss: 0.278258  [41600/60000]\n",
      "loss: 0.109787  [44800/60000]\n",
      "loss: 0.183402  [48000/60000]\n",
      "loss: 0.083432  [51200/60000]\n",
      "loss: 0.060411  [54400/60000]\n",
      "loss: 0.196644  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.128169 \n",
      "\n",
      "Epoch:  1\n",
      "--------------\n",
      "loss: 0.238189  [    0/60000]\n",
      "loss: 0.200970  [ 3200/60000]\n",
      "loss: 0.052697  [ 6400/60000]\n",
      "loss: 0.191619  [ 9600/60000]\n",
      "loss: 0.138887  [12800/60000]\n",
      "loss: 0.350413  [16000/60000]\n",
      "loss: 0.157491  [19200/60000]\n",
      "loss: 0.080814  [22400/60000]\n",
      "loss: 0.099795  [25600/60000]\n",
      "loss: 0.061887  [28800/60000]\n",
      "loss: 0.188573  [32000/60000]\n",
      "loss: 0.305361  [35200/60000]\n",
      "loss: 0.076832  [38400/60000]\n",
      "loss: 0.374182  [41600/60000]\n",
      "loss: 0.021405  [44800/60000]\n",
      "loss: 0.052291  [48000/60000]\n",
      "loss: 0.317223  [51200/60000]\n",
      "loss: 0.079278  [54400/60000]\n",
      "loss: 0.148927  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.084450 \n",
      "\n",
      "Epoch:  2\n",
      "--------------\n",
      "loss: 0.014401  [    0/60000]\n",
      "loss: 0.074804  [ 3200/60000]\n",
      "loss: 0.318283  [ 6400/60000]\n",
      "loss: 0.166273  [ 9600/60000]\n",
      "loss: 0.006766  [12800/60000]\n",
      "loss: 0.164276  [16000/60000]\n",
      "loss: 0.124771  [19200/60000]\n",
      "loss: 0.110757  [22400/60000]\n",
      "loss: 0.008062  [25600/60000]\n",
      "loss: 0.076813  [28800/60000]\n",
      "loss: 0.035675  [32000/60000]\n",
      "loss: 0.023889  [35200/60000]\n",
      "loss: 0.091081  [38400/60000]\n",
      "loss: 0.029147  [41600/60000]\n",
      "loss: 0.149993  [44800/60000]\n",
      "loss: 0.047772  [48000/60000]\n",
      "loss: 0.005666  [51200/60000]\n",
      "loss: 0.013993  [54400/60000]\n",
      "loss: 0.060534  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.068972 \n",
      "\n",
      "Epoch:  3\n",
      "--------------\n",
      "loss: 0.006506  [    0/60000]\n",
      "loss: 0.053498  [ 3200/60000]\n",
      "loss: 0.014076  [ 6400/60000]\n",
      "loss: 0.010217  [ 9600/60000]\n",
      "loss: 0.250764  [12800/60000]\n",
      "loss: 0.039513  [16000/60000]\n",
      "loss: 0.024589  [19200/60000]\n",
      "loss: 0.046955  [22400/60000]\n",
      "loss: 0.022612  [25600/60000]\n",
      "loss: 0.033085  [28800/60000]\n",
      "loss: 0.033225  [32000/60000]\n",
      "loss: 0.049209  [35200/60000]\n",
      "loss: 0.063953  [38400/60000]\n",
      "loss: 0.102599  [41600/60000]\n",
      "loss: 0.113983  [44800/60000]\n",
      "loss: 0.012485  [48000/60000]\n",
      "loss: 0.036955  [51200/60000]\n",
      "loss: 0.045534  [54400/60000]\n",
      "loss: 0.004510  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.054729 \n",
      "\n",
      "Epoch:  4\n",
      "--------------\n",
      "loss: 0.028125  [    0/60000]\n",
      "loss: 0.036429  [ 3200/60000]\n",
      "loss: 0.030495  [ 6400/60000]\n",
      "loss: 0.021483  [ 9600/60000]\n",
      "loss: 0.074965  [12800/60000]\n",
      "loss: 0.034530  [16000/60000]\n",
      "loss: 0.169734  [19200/60000]\n",
      "loss: 0.009089  [22400/60000]\n",
      "loss: 0.013236  [25600/60000]\n",
      "loss: 0.001633  [28800/60000]\n",
      "loss: 0.039519  [32000/60000]\n",
      "loss: 0.002678  [35200/60000]\n",
      "loss: 0.181664  [38400/60000]\n",
      "loss: 0.067721  [41600/60000]\n",
      "loss: 0.028203  [44800/60000]\n",
      "loss: 0.025922  [48000/60000]\n",
      "loss: 0.134986  [51200/60000]\n",
      "loss: 0.001942  [54400/60000]\n",
      "loss: 0.006914  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.054183 \n",
      "\n",
      "Epoch:  5\n",
      "--------------\n",
      "loss: 0.005899  [    0/60000]\n",
      "loss: 0.096057  [ 3200/60000]\n",
      "loss: 0.015822  [ 6400/60000]\n",
      "loss: 0.010994  [ 9600/60000]\n",
      "loss: 0.240284  [12800/60000]\n",
      "loss: 0.024651  [16000/60000]\n",
      "loss: 0.008818  [19200/60000]\n",
      "loss: 0.004810  [22400/60000]\n",
      "loss: 0.007786  [25600/60000]\n",
      "loss: 0.034073  [28800/60000]\n",
      "loss: 0.005753  [32000/60000]\n",
      "loss: 0.092317  [35200/60000]\n",
      "loss: 0.005956  [38400/60000]\n",
      "loss: 0.053561  [41600/60000]\n",
      "loss: 0.071646  [44800/60000]\n",
      "loss: 0.000982  [48000/60000]\n",
      "loss: 0.075996  [51200/60000]\n",
      "loss: 0.017557  [54400/60000]\n",
      "loss: 0.017635  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.050819 \n",
      "\n",
      "Epoch:  6\n",
      "--------------\n",
      "loss: 0.030205  [    0/60000]\n",
      "loss: 0.018164  [ 3200/60000]\n",
      "loss: 0.016965  [ 6400/60000]\n",
      "loss: 0.001099  [ 9600/60000]\n",
      "loss: 0.054310  [12800/60000]\n",
      "loss: 0.060341  [16000/60000]\n",
      "loss: 0.096765  [19200/60000]\n",
      "loss: 0.002871  [22400/60000]\n",
      "loss: 0.011107  [25600/60000]\n",
      "loss: 0.138865  [28800/60000]\n",
      "loss: 0.032865  [32000/60000]\n",
      "loss: 0.043900  [35200/60000]\n",
      "loss: 0.025172  [38400/60000]\n",
      "loss: 0.030832  [41600/60000]\n",
      "loss: 0.061295  [44800/60000]\n",
      "loss: 0.257153  [48000/60000]\n",
      "loss: 0.068452  [51200/60000]\n",
      "loss: 0.002453  [54400/60000]\n",
      "loss: 0.001721  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.044170 \n",
      "\n",
      "Epoch:  7\n",
      "--------------\n",
      "loss: 0.025255  [    0/60000]\n",
      "loss: 0.018382  [ 3200/60000]\n",
      "loss: 0.039736  [ 6400/60000]\n",
      "loss: 0.001311  [ 9600/60000]\n",
      "loss: 0.004687  [12800/60000]\n",
      "loss: 0.033033  [16000/60000]\n",
      "loss: 0.001366  [19200/60000]\n",
      "loss: 0.023615  [22400/60000]\n",
      "loss: 0.003554  [25600/60000]\n",
      "loss: 0.032441  [28800/60000]\n",
      "loss: 0.004092  [32000/60000]\n",
      "loss: 0.013280  [35200/60000]\n",
      "loss: 0.003887  [38400/60000]\n",
      "loss: 0.001213  [41600/60000]\n",
      "loss: 0.033257  [44800/60000]\n",
      "loss: 0.018907  [48000/60000]\n",
      "loss: 0.041287  [51200/60000]\n",
      "loss: 0.005910  [54400/60000]\n",
      "loss: 0.019694  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.045944 \n",
      "\n",
      "Epoch:  8\n",
      "--------------\n",
      "loss: 0.010853  [    0/60000]\n",
      "loss: 0.032464  [ 3200/60000]\n",
      "loss: 0.001352  [ 6400/60000]\n",
      "loss: 0.163811  [ 9600/60000]\n",
      "loss: 0.038627  [12800/60000]\n",
      "loss: 0.013596  [16000/60000]\n",
      "loss: 0.000967  [19200/60000]\n",
      "loss: 0.001497  [22400/60000]\n",
      "loss: 0.007086  [25600/60000]\n",
      "loss: 0.006345  [28800/60000]\n",
      "loss: 0.013798  [32000/60000]\n",
      "loss: 0.003465  [35200/60000]\n",
      "loss: 0.007336  [38400/60000]\n",
      "loss: 0.000840  [41600/60000]\n",
      "loss: 0.200511  [44800/60000]\n",
      "loss: 0.005267  [48000/60000]\n",
      "loss: 0.003476  [51200/60000]\n",
      "loss: 0.005073  [54400/60000]\n",
      "loss: 0.065645  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.043595 \n",
      "\n",
      "Epoch:  9\n",
      "--------------\n",
      "loss: 0.004170  [    0/60000]\n",
      "loss: 0.006043  [ 3200/60000]\n",
      "loss: 0.002148  [ 6400/60000]\n",
      "loss: 0.000767  [ 9600/60000]\n",
      "loss: 0.008608  [12800/60000]\n",
      "loss: 0.002173  [16000/60000]\n",
      "loss: 0.000728  [19200/60000]\n",
      "loss: 0.060234  [22400/60000]\n",
      "loss: 0.015278  [25600/60000]\n",
      "loss: 0.002080  [28800/60000]\n",
      "loss: 0.022855  [32000/60000]\n",
      "loss: 0.018038  [35200/60000]\n",
      "loss: 0.065944  [38400/60000]\n",
      "loss: 0.002646  [41600/60000]\n",
      "loss: 0.109072  [44800/60000]\n",
      "loss: 0.001711  [48000/60000]\n",
      "loss: 0.021998  [51200/60000]\n",
      "loss: 0.004001  [54400/60000]\n",
      "loss: 0.001038  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.041438 \n",
      "\n",
      "Epoch:  10\n",
      "--------------\n",
      "loss: 0.001320  [    0/60000]\n",
      "loss: 0.022463  [ 3200/60000]\n",
      "loss: 0.084039  [ 6400/60000]\n",
      "loss: 0.001571  [ 9600/60000]\n",
      "loss: 0.002614  [12800/60000]\n",
      "loss: 0.001747  [16000/60000]\n",
      "loss: 0.009280  [19200/60000]\n",
      "loss: 0.043025  [22400/60000]\n",
      "loss: 0.016439  [25600/60000]\n",
      "loss: 0.011076  [28800/60000]\n",
      "loss: 0.018738  [32000/60000]\n",
      "loss: 0.042825  [35200/60000]\n",
      "loss: 0.001045  [38400/60000]\n",
      "loss: 0.002552  [41600/60000]\n",
      "loss: 0.000648  [44800/60000]\n",
      "loss: 0.042069  [48000/60000]\n",
      "loss: 0.060534  [51200/60000]\n",
      "loss: 0.002796  [54400/60000]\n",
      "loss: 0.001802  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.041596 \n",
      "\n",
      "Epoch:  11\n",
      "--------------\n",
      "loss: 0.001723  [    0/60000]\n",
      "loss: 0.009377  [ 3200/60000]\n",
      "loss: 0.021918  [ 6400/60000]\n",
      "loss: 0.006683  [ 9600/60000]\n",
      "loss: 0.039669  [12800/60000]\n",
      "loss: 0.013994  [16000/60000]\n",
      "loss: 0.007158  [19200/60000]\n",
      "loss: 0.045915  [22400/60000]\n",
      "loss: 0.187538  [25600/60000]\n",
      "loss: 0.032361  [28800/60000]\n",
      "loss: 0.035242  [32000/60000]\n",
      "loss: 0.001857  [35200/60000]\n",
      "loss: 0.007883  [38400/60000]\n",
      "loss: 0.024897  [41600/60000]\n",
      "loss: 0.030247  [44800/60000]\n",
      "loss: 0.003978  [48000/60000]\n",
      "loss: 0.178796  [51200/60000]\n",
      "loss: 0.039991  [54400/60000]\n",
      "loss: 0.020354  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.041935 \n",
      "\n",
      "Epoch:  12\n",
      "--------------\n",
      "loss: 0.002124  [    0/60000]\n",
      "loss: 0.000301  [ 3200/60000]\n",
      "loss: 0.036478  [ 6400/60000]\n",
      "loss: 0.029756  [ 9600/60000]\n",
      "loss: 0.001052  [12800/60000]\n",
      "loss: 0.003444  [16000/60000]\n",
      "loss: 0.005474  [19200/60000]\n",
      "loss: 0.039752  [22400/60000]\n",
      "loss: 0.057084  [25600/60000]\n",
      "loss: 0.001589  [28800/60000]\n",
      "loss: 0.008757  [32000/60000]\n",
      "loss: 0.002793  [35200/60000]\n",
      "loss: 0.020681  [38400/60000]\n",
      "loss: 0.008721  [41600/60000]\n",
      "loss: 0.000357  [44800/60000]\n",
      "loss: 0.004435  [48000/60000]\n",
      "loss: 0.003918  [51200/60000]\n",
      "loss: 0.000506  [54400/60000]\n",
      "loss: 0.000518  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.044868 \n",
      "\n",
      "Epoch:  13\n",
      "--------------\n",
      "loss: 0.013579  [    0/60000]\n",
      "loss: 0.008330  [ 3200/60000]\n",
      "loss: 0.006613  [ 6400/60000]\n",
      "loss: 0.020228  [ 9600/60000]\n",
      "loss: 0.008815  [12800/60000]\n",
      "loss: 0.006525  [16000/60000]\n",
      "loss: 0.006485  [19200/60000]\n",
      "loss: 0.001834  [22400/60000]\n",
      "loss: 0.000590  [25600/60000]\n",
      "loss: 0.008376  [28800/60000]\n",
      "loss: 0.008037  [32000/60000]\n",
      "loss: 0.015452  [35200/60000]\n",
      "loss: 0.001633  [38400/60000]\n",
      "loss: 0.003340  [41600/60000]\n",
      "loss: 0.006450  [44800/60000]\n",
      "loss: 0.003224  [48000/60000]\n",
      "loss: 0.018320  [51200/60000]\n",
      "loss: 0.000255  [54400/60000]\n",
      "loss: 0.055411  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.047018 \n",
      "\n",
      "Epoch:  14\n",
      "--------------\n",
      "loss: 0.103553  [    0/60000]\n",
      "loss: 0.000700  [ 3200/60000]\n",
      "loss: 0.006454  [ 6400/60000]\n",
      "loss: 0.000323  [ 9600/60000]\n",
      "loss: 0.029508  [12800/60000]\n",
      "loss: 0.002492  [16000/60000]\n",
      "loss: 0.001108  [19200/60000]\n",
      "loss: 0.000917  [22400/60000]\n",
      "loss: 0.002898  [25600/60000]\n",
      "loss: 0.029022  [28800/60000]\n",
      "loss: 0.001281  [32000/60000]\n",
      "loss: 0.066276  [35200/60000]\n",
      "loss: 0.000633  [38400/60000]\n",
      "loss: 0.001429  [41600/60000]\n",
      "loss: 0.006502  [44800/60000]\n",
      "loss: 0.002049  [48000/60000]\n",
      "loss: 0.001110  [51200/60000]\n",
      "loss: 0.001584  [54400/60000]\n",
      "loss: 0.004827  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.048449 \n",
      "\n",
      "Epoch:  15\n",
      "--------------\n",
      "loss: 0.002507  [    0/60000]\n",
      "loss: 0.001124  [ 3200/60000]\n",
      "loss: 0.001802  [ 6400/60000]\n",
      "loss: 0.086536  [ 9600/60000]\n",
      "loss: 0.000292  [12800/60000]\n",
      "loss: 0.000374  [16000/60000]\n",
      "loss: 0.006408  [19200/60000]\n",
      "loss: 0.000911  [22400/60000]\n",
      "loss: 0.001422  [25600/60000]\n",
      "loss: 0.001853  [28800/60000]\n",
      "loss: 0.090200  [32000/60000]\n",
      "loss: 0.006297  [35200/60000]\n",
      "loss: 0.003384  [38400/60000]\n",
      "loss: 0.008734  [41600/60000]\n",
      "loss: 0.009249  [44800/60000]\n",
      "loss: 0.054872  [48000/60000]\n",
      "loss: 0.078074  [51200/60000]\n",
      "loss: 0.027639  [54400/60000]\n",
      "loss: 0.011398  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.042408 \n",
      "\n",
      "Epoch:  16\n",
      "--------------\n",
      "loss: 0.000225  [    0/60000]\n",
      "loss: 0.017521  [ 3200/60000]\n",
      "loss: 0.000666  [ 6400/60000]\n",
      "loss: 0.005678  [ 9600/60000]\n",
      "loss: 0.000484  [12800/60000]\n",
      "loss: 0.122322  [16000/60000]\n",
      "loss: 0.000037  [19200/60000]\n",
      "loss: 0.012868  [22400/60000]\n",
      "loss: 0.001962  [25600/60000]\n",
      "loss: 0.269621  [28800/60000]\n",
      "loss: 0.000067  [32000/60000]\n",
      "loss: 0.000293  [35200/60000]\n",
      "loss: 0.000886  [38400/60000]\n",
      "loss: 0.000719  [41600/60000]\n",
      "loss: 0.005825  [44800/60000]\n",
      "loss: 0.000460  [48000/60000]\n",
      "loss: 0.004313  [51200/60000]\n",
      "loss: 0.000460  [54400/60000]\n",
      "loss: 0.000481  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.046524 \n",
      "\n",
      "Epoch:  17\n",
      "--------------\n",
      "loss: 0.000150  [    0/60000]\n",
      "loss: 0.003992  [ 3200/60000]\n",
      "loss: 0.001161  [ 6400/60000]\n",
      "loss: 0.001439  [ 9600/60000]\n",
      "loss: 0.001763  [12800/60000]\n",
      "loss: 0.000396  [16000/60000]\n",
      "loss: 0.001816  [19200/60000]\n",
      "loss: 0.030581  [22400/60000]\n",
      "loss: 0.001189  [25600/60000]\n",
      "loss: 0.013837  [28800/60000]\n",
      "loss: 0.028725  [32000/60000]\n",
      "loss: 0.002444  [35200/60000]\n",
      "loss: 0.002897  [38400/60000]\n",
      "loss: 0.000147  [41600/60000]\n",
      "loss: 0.250197  [44800/60000]\n",
      "loss: 0.011035  [48000/60000]\n",
      "loss: 0.037034  [51200/60000]\n",
      "loss: 0.169208  [54400/60000]\n",
      "loss: 0.017238  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.044635 \n",
      "\n",
      "Epoch:  18\n",
      "--------------\n",
      "loss: 0.000058  [    0/60000]\n",
      "loss: 0.000291  [ 3200/60000]\n",
      "loss: 0.000466  [ 6400/60000]\n",
      "loss: 0.001458  [ 9600/60000]\n",
      "loss: 0.001255  [12800/60000]\n",
      "loss: 0.011780  [16000/60000]\n",
      "loss: 0.003908  [19200/60000]\n",
      "loss: 0.000023  [22400/60000]\n",
      "loss: 0.005496  [25600/60000]\n",
      "loss: 0.032195  [28800/60000]\n",
      "loss: 0.001327  [32000/60000]\n",
      "loss: 0.003100  [35200/60000]\n",
      "loss: 0.003969  [38400/60000]\n",
      "loss: 0.001633  [41600/60000]\n",
      "loss: 0.000215  [44800/60000]\n",
      "loss: 0.000056  [48000/60000]\n",
      "loss: 0.000253  [51200/60000]\n",
      "loss: 0.000469  [54400/60000]\n",
      "loss: 0.011405  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.045126 \n",
      "\n",
      "Epoch:  19\n",
      "--------------\n",
      "loss: 0.065961  [    0/60000]\n",
      "loss: 0.001612  [ 3200/60000]\n",
      "loss: 0.005739  [ 6400/60000]\n",
      "loss: 0.000277  [ 9600/60000]\n",
      "loss: 0.001027  [12800/60000]\n",
      "loss: 0.005060  [16000/60000]\n",
      "loss: 0.000671  [19200/60000]\n",
      "loss: 0.005170  [22400/60000]\n",
      "loss: 0.004701  [25600/60000]\n",
      "loss: 0.008074  [28800/60000]\n",
      "loss: 0.016634  [32000/60000]\n",
      "loss: 0.000249  [35200/60000]\n",
      "loss: 0.001329  [38400/60000]\n",
      "loss: 0.007072  [41600/60000]\n",
      "loss: 0.000835  [44800/60000]\n",
      "loss: 0.000277  [48000/60000]\n",
      "loss: 0.000065  [51200/60000]\n",
      "loss: 0.000657  [54400/60000]\n",
      "loss: 0.000404  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.048541 \n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print(\"Epoch: \", epoch)\n",
    "    print(\"--------------\") \n",
    "\n",
    "    running_loss = 0.0\n",
    "    size = len(trainloader.dataset)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cmodel2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(inputs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    size = len(testloader.dataset)\n",
    "    num_batches = len(testloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            #X = X.to(device)\n",
    "            #y = y.to(device)\n",
    "            pred = cmodel2(X)\n",
    "            test_loss += criterion(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = cmodel2(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN3(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten1): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 14 layer CNN model\n",
    "class CNN3(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN3,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.mp2 = nn.MaxPool2d(2)\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = self.flatten1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "cmodel3 = CNN3(28*28)\n",
    "optimizer = torch.optim.SGD(cmodel3.parameters(), lr = lr)\n",
    "print(cmodel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CNN3                                     [32, 1, 28, 28]           [32, 10]                  --\n",
       "‚îú‚îÄConv2d: 1-1                            [32, 1, 28, 28]           [32, 6, 28, 28]           156\n",
       "‚îú‚îÄBatchNorm2d: 1-2                       [32, 6, 28, 28]           [32, 6, 28, 28]           12\n",
       "‚îú‚îÄReLU: 1-3                              [32, 6, 28, 28]           [32, 6, 28, 28]           --\n",
       "‚îú‚îÄMaxPool2d: 1-4                         [32, 6, 28, 28]           [32, 6, 14, 14]           --\n",
       "‚îú‚îÄConv2d: 1-5                            [32, 6, 14, 14]           [32, 16, 14, 14]          2,416\n",
       "‚îú‚îÄBatchNorm2d: 1-6                       [32, 16, 14, 14]          [32, 16, 14, 14]          32\n",
       "‚îú‚îÄReLU: 1-7                              [32, 16, 14, 14]          [32, 16, 14, 14]          --\n",
       "‚îú‚îÄMaxPool2d: 1-8                         [32, 16, 14, 14]          [32, 16, 7, 7]            --\n",
       "‚îú‚îÄFlatten: 1-9                           [32, 16, 7, 7]            [32, 784]                 --\n",
       "‚îú‚îÄLinear: 1-10                           [32, 784]                 [32, 120]                 94,200\n",
       "‚îú‚îÄReLU: 1-11                             [32, 120]                 [32, 120]                 --\n",
       "‚îú‚îÄLinear: 1-12                           [32, 120]                 [32, 84]                  10,164\n",
       "‚îú‚îÄReLU: 1-13                             [32, 84]                  [32, 84]                  --\n",
       "‚îú‚îÄLinear: 1-14                           [32, 84]                  [32, 10]                  850\n",
       "===================================================================================================================\n",
       "Total params: 107,830\n",
       "Trainable params: 107,830\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 22.44\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 4.07\n",
       "Params size (MB): 0.43\n",
       "Estimated Total Size (MB): 4.60\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 32 #for illustration\n",
    "\n",
    "summary(cmodel3, input_size=(batch_size, 1, 28, 28), device='cpu', col_names=['input_size', 'output_size',\n",
    "                                                                        'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "--------------\n",
      "loss: 2.368721  [    0/60000]\n",
      "loss: 1.870274  [ 3200/60000]\n",
      "loss: 0.649747  [ 6400/60000]\n",
      "loss: 0.484343  [ 9600/60000]\n",
      "loss: 0.316339  [12800/60000]\n",
      "loss: 0.271136  [16000/60000]\n",
      "loss: 0.148764  [19200/60000]\n",
      "loss: 0.073224  [22400/60000]\n",
      "loss: 0.318970  [25600/60000]\n",
      "loss: 0.274843  [28800/60000]\n",
      "loss: 0.093480  [32000/60000]\n",
      "loss: 0.146383  [35200/60000]\n",
      "loss: 0.132766  [38400/60000]\n",
      "loss: 0.157624  [41600/60000]\n",
      "loss: 0.119542  [44800/60000]\n",
      "loss: 0.084574  [48000/60000]\n",
      "loss: 0.080631  [51200/60000]\n",
      "loss: 0.301349  [54400/60000]\n",
      "loss: 0.048410  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.086805 \n",
      "\n",
      "Epoch:  1\n",
      "--------------\n",
      "loss: 0.097615  [    0/60000]\n",
      "loss: 0.038653  [ 3200/60000]\n",
      "loss: 0.071032  [ 6400/60000]\n",
      "loss: 0.151115  [ 9600/60000]\n",
      "loss: 0.066190  [12800/60000]\n",
      "loss: 0.087166  [16000/60000]\n",
      "loss: 0.151678  [19200/60000]\n",
      "loss: 0.026919  [22400/60000]\n",
      "loss: 0.201039  [25600/60000]\n",
      "loss: 0.011729  [28800/60000]\n",
      "loss: 0.032659  [32000/60000]\n",
      "loss: 0.010646  [35200/60000]\n",
      "loss: 0.042015  [38400/60000]\n",
      "loss: 0.176737  [41600/60000]\n",
      "loss: 0.094988  [44800/60000]\n",
      "loss: 0.035137  [48000/60000]\n",
      "loss: 0.014103  [51200/60000]\n",
      "loss: 0.008350  [54400/60000]\n",
      "loss: 0.056591  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.063666 \n",
      "\n",
      "Epoch:  2\n",
      "--------------\n",
      "loss: 0.077153  [    0/60000]\n",
      "loss: 0.071691  [ 3200/60000]\n",
      "loss: 0.130113  [ 6400/60000]\n",
      "loss: 0.036423  [ 9600/60000]\n",
      "loss: 0.047369  [12800/60000]\n",
      "loss: 0.006175  [16000/60000]\n",
      "loss: 0.022705  [19200/60000]\n",
      "loss: 0.033248  [22400/60000]\n",
      "loss: 0.080407  [25600/60000]\n",
      "loss: 0.031707  [28800/60000]\n",
      "loss: 0.048846  [32000/60000]\n",
      "loss: 0.067825  [35200/60000]\n",
      "loss: 0.026542  [38400/60000]\n",
      "loss: 0.127395  [41600/60000]\n",
      "loss: 0.037624  [44800/60000]\n",
      "loss: 0.014449  [48000/60000]\n",
      "loss: 0.026360  [51200/60000]\n",
      "loss: 0.015623  [54400/60000]\n",
      "loss: 0.235151  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.048616 \n",
      "\n",
      "Epoch:  3\n",
      "--------------\n",
      "loss: 0.014080  [    0/60000]\n",
      "loss: 0.013437  [ 3200/60000]\n",
      "loss: 0.053950  [ 6400/60000]\n",
      "loss: 0.141080  [ 9600/60000]\n",
      "loss: 0.030693  [12800/60000]\n",
      "loss: 0.110039  [16000/60000]\n",
      "loss: 0.170858  [19200/60000]\n",
      "loss: 0.132843  [22400/60000]\n",
      "loss: 0.070794  [25600/60000]\n",
      "loss: 0.003195  [28800/60000]\n",
      "loss: 0.198039  [32000/60000]\n",
      "loss: 0.020217  [35200/60000]\n",
      "loss: 0.024379  [38400/60000]\n",
      "loss: 0.024748  [41600/60000]\n",
      "loss: 0.005537  [44800/60000]\n",
      "loss: 0.009212  [48000/60000]\n",
      "loss: 0.012620  [51200/60000]\n",
      "loss: 0.004645  [54400/60000]\n",
      "loss: 0.104039  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.048829 \n",
      "\n",
      "Epoch:  4\n",
      "--------------\n",
      "loss: 0.039528  [    0/60000]\n",
      "loss: 0.002133  [ 3200/60000]\n",
      "loss: 0.017201  [ 6400/60000]\n",
      "loss: 0.084390  [ 9600/60000]\n",
      "loss: 0.019567  [12800/60000]\n",
      "loss: 0.004035  [16000/60000]\n",
      "loss: 0.003363  [19200/60000]\n",
      "loss: 0.133688  [22400/60000]\n",
      "loss: 0.003855  [25600/60000]\n",
      "loss: 0.024082  [28800/60000]\n",
      "loss: 0.013809  [32000/60000]\n",
      "loss: 0.034550  [35200/60000]\n",
      "loss: 0.108277  [38400/60000]\n",
      "loss: 0.106162  [41600/60000]\n",
      "loss: 0.024021  [44800/60000]\n",
      "loss: 0.006352  [48000/60000]\n",
      "loss: 0.006357  [51200/60000]\n",
      "loss: 0.003759  [54400/60000]\n",
      "loss: 0.002695  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.043316 \n",
      "\n",
      "Epoch:  5\n",
      "--------------\n",
      "loss: 0.084624  [    0/60000]\n",
      "loss: 0.004693  [ 3200/60000]\n",
      "loss: 0.010118  [ 6400/60000]\n",
      "loss: 0.094970  [ 9600/60000]\n",
      "loss: 0.195265  [12800/60000]\n",
      "loss: 0.007048  [16000/60000]\n",
      "loss: 0.024525  [19200/60000]\n",
      "loss: 0.058142  [22400/60000]\n",
      "loss: 0.062408  [25600/60000]\n",
      "loss: 0.016539  [28800/60000]\n",
      "loss: 0.055034  [32000/60000]\n",
      "loss: 0.051152  [35200/60000]\n",
      "loss: 0.007778  [38400/60000]\n",
      "loss: 0.095031  [41600/60000]\n",
      "loss: 0.015710  [44800/60000]\n",
      "loss: 0.004364  [48000/60000]\n",
      "loss: 0.048273  [51200/60000]\n",
      "loss: 0.024033  [54400/60000]\n",
      "loss: 0.008745  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.038720 \n",
      "\n",
      "Epoch:  6\n",
      "--------------\n",
      "loss: 0.012710  [    0/60000]\n",
      "loss: 0.003503  [ 3200/60000]\n",
      "loss: 0.024907  [ 6400/60000]\n",
      "loss: 0.032535  [ 9600/60000]\n",
      "loss: 0.175568  [12800/60000]\n",
      "loss: 0.034794  [16000/60000]\n",
      "loss: 0.092974  [19200/60000]\n",
      "loss: 0.000598  [22400/60000]\n",
      "loss: 0.084597  [25600/60000]\n",
      "loss: 0.011041  [28800/60000]\n",
      "loss: 0.002647  [32000/60000]\n",
      "loss: 0.002260  [35200/60000]\n",
      "loss: 0.003278  [38400/60000]\n",
      "loss: 0.008091  [41600/60000]\n",
      "loss: 0.016920  [44800/60000]\n",
      "loss: 0.078941  [48000/60000]\n",
      "loss: 0.006403  [51200/60000]\n",
      "loss: 0.014449  [54400/60000]\n",
      "loss: 0.008050  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.038287 \n",
      "\n",
      "Epoch:  7\n",
      "--------------\n",
      "loss: 0.011307  [    0/60000]\n",
      "loss: 0.012212  [ 3200/60000]\n",
      "loss: 0.124983  [ 6400/60000]\n",
      "loss: 0.010467  [ 9600/60000]\n",
      "loss: 0.001311  [12800/60000]\n",
      "loss: 0.001786  [16000/60000]\n",
      "loss: 0.001940  [19200/60000]\n",
      "loss: 0.018251  [22400/60000]\n",
      "loss: 0.007500  [25600/60000]\n",
      "loss: 0.009241  [28800/60000]\n",
      "loss: 0.007590  [32000/60000]\n",
      "loss: 0.005378  [35200/60000]\n",
      "loss: 0.003463  [38400/60000]\n",
      "loss: 0.001815  [41600/60000]\n",
      "loss: 0.194818  [44800/60000]\n",
      "loss: 0.075202  [48000/60000]\n",
      "loss: 0.082577  [51200/60000]\n",
      "loss: 0.163623  [54400/60000]\n",
      "loss: 0.070908  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.034194 \n",
      "\n",
      "Epoch:  8\n",
      "--------------\n",
      "loss: 0.007631  [    0/60000]\n",
      "loss: 0.016703  [ 3200/60000]\n",
      "loss: 0.029560  [ 6400/60000]\n",
      "loss: 0.002698  [ 9600/60000]\n",
      "loss: 0.096280  [12800/60000]\n",
      "loss: 0.001949  [16000/60000]\n",
      "loss: 0.001044  [19200/60000]\n",
      "loss: 0.024723  [22400/60000]\n",
      "loss: 0.002884  [25600/60000]\n",
      "loss: 0.002743  [28800/60000]\n",
      "loss: 0.002913  [32000/60000]\n",
      "loss: 0.003697  [35200/60000]\n",
      "loss: 0.046822  [38400/60000]\n",
      "loss: 0.004159  [41600/60000]\n",
      "loss: 0.035667  [44800/60000]\n",
      "loss: 0.008756  [48000/60000]\n",
      "loss: 0.012335  [51200/60000]\n",
      "loss: 0.003142  [54400/60000]\n",
      "loss: 0.016120  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.033470 \n",
      "\n",
      "Epoch:  9\n",
      "--------------\n",
      "loss: 0.001026  [    0/60000]\n",
      "loss: 0.026909  [ 3200/60000]\n",
      "loss: 0.006937  [ 6400/60000]\n",
      "loss: 0.029384  [ 9600/60000]\n",
      "loss: 0.005782  [12800/60000]\n",
      "loss: 0.004870  [16000/60000]\n",
      "loss: 0.023672  [19200/60000]\n",
      "loss: 0.196204  [22400/60000]\n",
      "loss: 0.014964  [25600/60000]\n",
      "loss: 0.013357  [28800/60000]\n",
      "loss: 0.033911  [32000/60000]\n",
      "loss: 0.000576  [35200/60000]\n",
      "loss: 0.003763  [38400/60000]\n",
      "loss: 0.010672  [41600/60000]\n",
      "loss: 0.090040  [44800/60000]\n",
      "loss: 0.000451  [48000/60000]\n",
      "loss: 0.118994  [51200/60000]\n",
      "loss: 0.030062  [54400/60000]\n",
      "loss: 0.002986  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.032529 \n",
      "\n",
      "Epoch:  10\n",
      "--------------\n",
      "loss: 0.026282  [    0/60000]\n",
      "loss: 0.024555  [ 3200/60000]\n",
      "loss: 0.003354  [ 6400/60000]\n",
      "loss: 0.002225  [ 9600/60000]\n",
      "loss: 0.000762  [12800/60000]\n",
      "loss: 0.050255  [16000/60000]\n",
      "loss: 0.032557  [19200/60000]\n",
      "loss: 0.015911  [22400/60000]\n",
      "loss: 0.007466  [25600/60000]\n",
      "loss: 0.005099  [28800/60000]\n",
      "loss: 0.008816  [32000/60000]\n",
      "loss: 0.003644  [35200/60000]\n",
      "loss: 0.001351  [38400/60000]\n",
      "loss: 0.069447  [41600/60000]\n",
      "loss: 0.030277  [44800/60000]\n",
      "loss: 0.000674  [48000/60000]\n",
      "loss: 0.002171  [51200/60000]\n",
      "loss: 0.055970  [54400/60000]\n",
      "loss: 0.002281  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.033560 \n",
      "\n",
      "Epoch:  11\n",
      "--------------\n",
      "loss: 0.005698  [    0/60000]\n",
      "loss: 0.006005  [ 3200/60000]\n",
      "loss: 0.004660  [ 6400/60000]\n",
      "loss: 0.016198  [ 9600/60000]\n",
      "loss: 0.003528  [12800/60000]\n",
      "loss: 0.001594  [16000/60000]\n",
      "loss: 0.001773  [19200/60000]\n",
      "loss: 0.101723  [22400/60000]\n",
      "loss: 0.056171  [25600/60000]\n",
      "loss: 0.005429  [28800/60000]\n",
      "loss: 0.009977  [32000/60000]\n",
      "loss: 0.010143  [35200/60000]\n",
      "loss: 0.003009  [38400/60000]\n",
      "loss: 0.001516  [41600/60000]\n",
      "loss: 0.001267  [44800/60000]\n",
      "loss: 0.044335  [48000/60000]\n",
      "loss: 0.007944  [51200/60000]\n",
      "loss: 0.052008  [54400/60000]\n",
      "loss: 0.000633  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.029345 \n",
      "\n",
      "Epoch:  12\n",
      "--------------\n",
      "loss: 0.000090  [    0/60000]\n",
      "loss: 0.010421  [ 3200/60000]\n",
      "loss: 0.032875  [ 6400/60000]\n",
      "loss: 0.004571  [ 9600/60000]\n",
      "loss: 0.008356  [12800/60000]\n",
      "loss: 0.003359  [16000/60000]\n",
      "loss: 0.027516  [19200/60000]\n",
      "loss: 0.006924  [22400/60000]\n",
      "loss: 0.015050  [25600/60000]\n",
      "loss: 0.005473  [28800/60000]\n",
      "loss: 0.001884  [32000/60000]\n",
      "loss: 0.000585  [35200/60000]\n",
      "loss: 0.024113  [38400/60000]\n",
      "loss: 0.004271  [41600/60000]\n",
      "loss: 0.000333  [44800/60000]\n",
      "loss: 0.004066  [48000/60000]\n",
      "loss: 0.001170  [51200/60000]\n",
      "loss: 0.002729  [54400/60000]\n",
      "loss: 0.000153  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.030455 \n",
      "\n",
      "Epoch:  13\n",
      "--------------\n",
      "loss: 0.005215  [    0/60000]\n",
      "loss: 0.027305  [ 3200/60000]\n",
      "loss: 0.000502  [ 6400/60000]\n",
      "loss: 0.015562  [ 9600/60000]\n",
      "loss: 0.009244  [12800/60000]\n",
      "loss: 0.040795  [16000/60000]\n",
      "loss: 0.006796  [19200/60000]\n",
      "loss: 0.004336  [22400/60000]\n",
      "loss: 0.014312  [25600/60000]\n",
      "loss: 0.001588  [28800/60000]\n",
      "loss: 0.090685  [32000/60000]\n",
      "loss: 0.061059  [35200/60000]\n",
      "loss: 0.001162  [38400/60000]\n",
      "loss: 0.029468  [41600/60000]\n",
      "loss: 0.017661  [44800/60000]\n",
      "loss: 0.007627  [48000/60000]\n",
      "loss: 0.000825  [51200/60000]\n",
      "loss: 0.013357  [54400/60000]\n",
      "loss: 0.005592  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.027852 \n",
      "\n",
      "Epoch:  14\n",
      "--------------\n",
      "loss: 0.013934  [    0/60000]\n",
      "loss: 0.001700  [ 3200/60000]\n",
      "loss: 0.000524  [ 6400/60000]\n",
      "loss: 0.012522  [ 9600/60000]\n",
      "loss: 0.006147  [12800/60000]\n",
      "loss: 0.002571  [16000/60000]\n",
      "loss: 0.000997  [19200/60000]\n",
      "loss: 0.000208  [22400/60000]\n",
      "loss: 0.060001  [25600/60000]\n",
      "loss: 0.014072  [28800/60000]\n",
      "loss: 0.002104  [32000/60000]\n",
      "loss: 0.025140  [35200/60000]\n",
      "loss: 0.019142  [38400/60000]\n",
      "loss: 0.039450  [41600/60000]\n",
      "loss: 0.037380  [44800/60000]\n",
      "loss: 0.001266  [48000/60000]\n",
      "loss: 0.005432  [51200/60000]\n",
      "loss: 0.148656  [54400/60000]\n",
      "loss: 0.000838  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.033744 \n",
      "\n",
      "Epoch:  15\n",
      "--------------\n",
      "loss: 0.005847  [    0/60000]\n",
      "loss: 0.000614  [ 3200/60000]\n",
      "loss: 0.015451  [ 6400/60000]\n",
      "loss: 0.007300  [ 9600/60000]\n",
      "loss: 0.007508  [12800/60000]\n",
      "loss: 0.017295  [16000/60000]\n",
      "loss: 0.003697  [19200/60000]\n",
      "loss: 0.005201  [22400/60000]\n",
      "loss: 0.002948  [25600/60000]\n",
      "loss: 0.155801  [28800/60000]\n",
      "loss: 0.005824  [32000/60000]\n",
      "loss: 0.003934  [35200/60000]\n",
      "loss: 0.002856  [38400/60000]\n",
      "loss: 0.000120  [41600/60000]\n",
      "loss: 0.002885  [44800/60000]\n",
      "loss: 0.018537  [48000/60000]\n",
      "loss: 0.013550  [51200/60000]\n",
      "loss: 0.002759  [54400/60000]\n",
      "loss: 0.001236  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.033100 \n",
      "\n",
      "Epoch:  16\n",
      "--------------\n",
      "loss: 0.039813  [    0/60000]\n",
      "loss: 0.001180  [ 3200/60000]\n",
      "loss: 0.003277  [ 6400/60000]\n",
      "loss: 0.001418  [ 9600/60000]\n",
      "loss: 0.001030  [12800/60000]\n",
      "loss: 0.013663  [16000/60000]\n",
      "loss: 0.000978  [19200/60000]\n",
      "loss: 0.003761  [22400/60000]\n",
      "loss: 0.012401  [25600/60000]\n",
      "loss: 0.000713  [28800/60000]\n",
      "loss: 0.004643  [32000/60000]\n",
      "loss: 0.027647  [35200/60000]\n",
      "loss: 0.003536  [38400/60000]\n",
      "loss: 0.002707  [41600/60000]\n",
      "loss: 0.002985  [44800/60000]\n",
      "loss: 0.002554  [48000/60000]\n",
      "loss: 0.002679  [51200/60000]\n",
      "loss: 0.000973  [54400/60000]\n",
      "loss: 0.018071  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.031910 \n",
      "\n",
      "Epoch:  17\n",
      "--------------\n",
      "loss: 0.014550  [    0/60000]\n",
      "loss: 0.002769  [ 3200/60000]\n",
      "loss: 0.024098  [ 6400/60000]\n",
      "loss: 0.007522  [ 9600/60000]\n",
      "loss: 0.001087  [12800/60000]\n",
      "loss: 0.009023  [16000/60000]\n",
      "loss: 0.002996  [19200/60000]\n",
      "loss: 0.000108  [22400/60000]\n",
      "loss: 0.006541  [25600/60000]\n",
      "loss: 0.000669  [28800/60000]\n",
      "loss: 0.013403  [32000/60000]\n",
      "loss: 0.005695  [35200/60000]\n",
      "loss: 0.052177  [38400/60000]\n",
      "loss: 0.038352  [41600/60000]\n",
      "loss: 0.042731  [44800/60000]\n",
      "loss: 0.011956  [48000/60000]\n",
      "loss: 0.014119  [51200/60000]\n",
      "loss: 0.002540  [54400/60000]\n",
      "loss: 0.014372  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.030582 \n",
      "\n",
      "Epoch:  18\n",
      "--------------\n",
      "loss: 0.011002  [    0/60000]\n",
      "loss: 0.009409  [ 3200/60000]\n",
      "loss: 0.006708  [ 6400/60000]\n",
      "loss: 0.007340  [ 9600/60000]\n",
      "loss: 0.002486  [12800/60000]\n",
      "loss: 0.000771  [16000/60000]\n",
      "loss: 0.000254  [19200/60000]\n",
      "loss: 0.000185  [22400/60000]\n",
      "loss: 0.034437  [25600/60000]\n",
      "loss: 0.001188  [28800/60000]\n",
      "loss: 0.019212  [32000/60000]\n",
      "loss: 0.037692  [35200/60000]\n",
      "loss: 0.004787  [38400/60000]\n",
      "loss: 0.002355  [41600/60000]\n",
      "loss: 0.001032  [44800/60000]\n",
      "loss: 0.002641  [48000/60000]\n",
      "loss: 0.002747  [51200/60000]\n",
      "loss: 0.008802  [54400/60000]\n",
      "loss: 0.000818  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.030659 \n",
      "\n",
      "Epoch:  19\n",
      "--------------\n",
      "loss: 0.003927  [    0/60000]\n",
      "loss: 0.001375  [ 3200/60000]\n",
      "loss: 0.000368  [ 6400/60000]\n",
      "loss: 0.000987  [ 9600/60000]\n",
      "loss: 0.000879  [12800/60000]\n",
      "loss: 0.001831  [16000/60000]\n",
      "loss: 0.008205  [19200/60000]\n",
      "loss: 0.009734  [22400/60000]\n",
      "loss: 0.011789  [25600/60000]\n",
      "loss: 0.011304  [28800/60000]\n",
      "loss: 0.002044  [32000/60000]\n",
      "loss: 0.000090  [35200/60000]\n",
      "loss: 0.000404  [38400/60000]\n",
      "loss: 0.001056  [41600/60000]\n",
      "loss: 0.000161  [44800/60000]\n",
      "loss: 0.005409  [48000/60000]\n",
      "loss: 0.011483  [51200/60000]\n",
      "loss: 0.035853  [54400/60000]\n",
      "loss: 0.003885  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.034867 \n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print(\"Epoch: \", epoch)\n",
    "    print(\"--------------\") \n",
    "\n",
    "    running_loss = 0.0\n",
    "    size = len(trainloader.dataset)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cmodel3(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(inputs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    size = len(testloader.dataset)\n",
    "    num_batches = len(testloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            #X = X.to(device)\n",
    "            #y = y.to(device)\n",
    "            pred = cmodel3(X)\n",
    "            test_loss += criterion(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = cmodel3(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the three models had the least amount of error for validation? \n",
    "The 4 layer, the 8 layer, and 14 layer model had an outstanding accuracy of 98% after testing them against the test dataset.\n",
    "\n",
    "How long it took to train each model?\n",
    "    a. The 4 layer model took around 8 minutes 31.2 seconds to train. \n",
    "    b. The 8 layer model took 15 minutes 32.5 seconds to train\n",
    "    c. The 14 layer model took around 10 minutes 38 seconds to train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN4(\n",
      "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=12544, out_features=84, bias=True)\n",
      "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.001567, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# Bonus CNN model\n",
    "class CNN4(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN4,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 128, 3, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.mp1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(128, 64, 3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(12544, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        self.dropout = nn.Dropout(0.001567)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "cmodel4 = CNN4(28*28)\n",
    "optimizer = torch.optim.SGD(cmodel4.parameters(), lr = lr)\n",
    "print(cmodel4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "c:\\Users\\aj824\\anaconda3\\envs\\pt2\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CNN4                                     [32, 1, 28, 28]           [32, 10]                  --\n",
       "‚îú‚îÄConv2d: 1-1                            [32, 1, 28, 28]           [32, 128, 28, 28]         1,280\n",
       "‚îú‚îÄBatchNorm2d: 1-2                       [32, 128, 28, 28]         [32, 128, 28, 28]         256\n",
       "‚îú‚îÄMaxPool2d: 1-3                         [32, 128, 28, 28]         [32, 128, 14, 14]         --\n",
       "‚îú‚îÄConv2d: 1-4                            [32, 128, 14, 14]         [32, 64, 14, 14]          73,792\n",
       "‚îú‚îÄBatchNorm2d: 1-5                       [32, 64, 14, 14]          [32, 64, 14, 14]          128\n",
       "‚îú‚îÄReLU: 1-6                              [32, 64, 14, 14]          [32, 64, 14, 14]          --\n",
       "‚îú‚îÄFlatten: 1-7                           [32, 64, 14, 14]          [32, 12544]               --\n",
       "‚îú‚îÄLinear: 1-8                            [32, 12544]               [32, 84]                  1,053,780\n",
       "‚îú‚îÄLinear: 1-9                            [32, 84]                  [32, 10]                  850\n",
       "‚îú‚îÄDropout: 1-10                          [32, 10]                  [32, 10]                  --\n",
       "===================================================================================================================\n",
       "Total params: 1,130,086\n",
       "Trainable params: 1,130,086\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 528.70\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 57.83\n",
       "Params size (MB): 4.52\n",
       "Estimated Total Size (MB): 62.45\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 32 #for illustration\n",
    "\n",
    "summary(cmodel4, input_size=(batch_size, 1, 28, 28), device='cpu', col_names=['input_size', 'output_size',\n",
    "                                                                        'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "--------------\n",
      "loss: 2.317155  [    0/60000]\n",
      "loss: 0.482956  [ 3200/60000]\n",
      "loss: 0.186918  [ 6400/60000]\n",
      "loss: 0.472008  [ 9600/60000]\n",
      "loss: 0.061528  [12800/60000]\n",
      "loss: 0.029174  [16000/60000]\n",
      "loss: 0.182370  [19200/60000]\n",
      "loss: 0.259084  [22400/60000]\n",
      "loss: 0.236645  [25600/60000]\n",
      "loss: 0.049582  [28800/60000]\n",
      "loss: 0.063481  [32000/60000]\n",
      "loss: 0.082781  [35200/60000]\n",
      "loss: 0.052535  [38400/60000]\n",
      "loss: 0.036721  [41600/60000]\n",
      "loss: 0.069316  [44800/60000]\n",
      "loss: 0.030191  [48000/60000]\n",
      "loss: 0.067719  [51200/60000]\n",
      "loss: 0.031561  [54400/60000]\n",
      "loss: 0.068664  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.062026 \n",
      "\n",
      "Epoch:  1\n",
      "--------------\n",
      "loss: 0.026473  [    0/60000]\n",
      "loss: 0.034438  [ 3200/60000]\n",
      "loss: 0.045464  [ 6400/60000]\n",
      "loss: 0.080597  [ 9600/60000]\n",
      "loss: 0.060768  [12800/60000]\n",
      "loss: 0.007286  [16000/60000]\n",
      "loss: 0.027299  [19200/60000]\n",
      "loss: 0.006267  [22400/60000]\n",
      "loss: 0.014494  [25600/60000]\n",
      "loss: 0.022376  [28800/60000]\n",
      "loss: 0.004967  [32000/60000]\n",
      "loss: 0.015597  [35200/60000]\n",
      "loss: 0.005898  [38400/60000]\n",
      "loss: 0.041640  [41600/60000]\n",
      "loss: 0.028612  [44800/60000]\n",
      "loss: 0.150121  [48000/60000]\n",
      "loss: 0.009521  [51200/60000]\n",
      "loss: 0.003952  [54400/60000]\n",
      "loss: 0.013240  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.046216 \n",
      "\n",
      "Epoch:  2\n",
      "--------------\n",
      "loss: 0.007264  [    0/60000]\n",
      "loss: 0.008421  [ 3200/60000]\n",
      "loss: 0.010990  [ 6400/60000]\n",
      "loss: 0.031446  [ 9600/60000]\n",
      "loss: 0.013468  [12800/60000]\n",
      "loss: 0.018353  [16000/60000]\n",
      "loss: 0.057456  [19200/60000]\n",
      "loss: 0.013088  [22400/60000]\n",
      "loss: 0.034349  [25600/60000]\n",
      "loss: 0.083099  [28800/60000]\n",
      "loss: 0.012040  [32000/60000]\n",
      "loss: 0.004837  [35200/60000]\n",
      "loss: 0.006202  [38400/60000]\n",
      "loss: 0.124565  [41600/60000]\n",
      "loss: 0.132902  [44800/60000]\n",
      "loss: 0.038438  [48000/60000]\n",
      "loss: 0.022741  [51200/60000]\n",
      "loss: 0.003674  [54400/60000]\n",
      "loss: 0.093399  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.041770 \n",
      "\n",
      "Epoch:  3\n",
      "--------------\n",
      "loss: 0.022572  [    0/60000]\n",
      "loss: 0.129540  [ 3200/60000]\n",
      "loss: 0.009966  [ 6400/60000]\n",
      "loss: 0.003415  [ 9600/60000]\n",
      "loss: 0.031361  [12800/60000]\n",
      "loss: 0.014338  [16000/60000]\n",
      "loss: 0.005085  [19200/60000]\n",
      "loss: 0.026811  [22400/60000]\n",
      "loss: 0.042981  [25600/60000]\n",
      "loss: 0.012841  [28800/60000]\n",
      "loss: 0.005209  [32000/60000]\n",
      "loss: 0.005197  [35200/60000]\n",
      "loss: 0.014757  [38400/60000]\n",
      "loss: 0.037831  [41600/60000]\n",
      "loss: 0.013379  [44800/60000]\n",
      "loss: 0.008345  [48000/60000]\n",
      "loss: 0.002498  [51200/60000]\n",
      "loss: 0.003019  [54400/60000]\n",
      "loss: 0.015952  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.041227 \n",
      "\n",
      "Epoch:  4\n",
      "--------------\n",
      "loss: 0.002968  [    0/60000]\n",
      "loss: 0.006606  [ 3200/60000]\n",
      "loss: 0.005521  [ 6400/60000]\n",
      "loss: 0.000845  [ 9600/60000]\n",
      "loss: 0.011068  [12800/60000]\n",
      "loss: 0.005308  [16000/60000]\n",
      "loss: 0.007525  [19200/60000]\n",
      "loss: 0.098992  [22400/60000]\n",
      "loss: 0.039285  [25600/60000]\n",
      "loss: 0.008032  [28800/60000]\n",
      "loss: 0.035108  [32000/60000]\n",
      "loss: 0.018691  [35200/60000]\n",
      "loss: 0.004074  [38400/60000]\n",
      "loss: 0.002564  [41600/60000]\n",
      "loss: 0.002614  [44800/60000]\n",
      "loss: 0.006163  [48000/60000]\n",
      "loss: 0.046928  [51200/60000]\n",
      "loss: 0.120096  [54400/60000]\n",
      "loss: 0.002912  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.035565 \n",
      "\n",
      "Epoch:  5\n",
      "--------------\n",
      "loss: 0.007225  [    0/60000]\n",
      "loss: 0.017033  [ 3200/60000]\n",
      "loss: 0.298818  [ 6400/60000]\n",
      "loss: 0.001298  [ 9600/60000]\n",
      "loss: 0.002664  [12800/60000]\n",
      "loss: 0.023756  [16000/60000]\n",
      "loss: 0.001328  [19200/60000]\n",
      "loss: 0.003373  [22400/60000]\n",
      "loss: 0.019813  [25600/60000]\n",
      "loss: 0.012980  [28800/60000]\n",
      "loss: 0.006291  [32000/60000]\n",
      "loss: 0.020527  [35200/60000]\n",
      "loss: 0.090356  [38400/60000]\n",
      "loss: 0.005359  [41600/60000]\n",
      "loss: 0.043473  [44800/60000]\n",
      "loss: 0.003728  [48000/60000]\n",
      "loss: 0.038095  [51200/60000]\n",
      "loss: 0.001720  [54400/60000]\n",
      "loss: 0.004080  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.034523 \n",
      "\n",
      "Epoch:  6\n",
      "--------------\n",
      "loss: 0.031341  [    0/60000]\n",
      "loss: 0.001205  [ 3200/60000]\n",
      "loss: 0.015892  [ 6400/60000]\n",
      "loss: 0.007387  [ 9600/60000]\n",
      "loss: 0.015430  [12800/60000]\n",
      "loss: 0.126640  [16000/60000]\n",
      "loss: 0.009469  [19200/60000]\n",
      "loss: 0.001176  [22400/60000]\n",
      "loss: 0.000902  [25600/60000]\n",
      "loss: 0.019870  [28800/60000]\n",
      "loss: 0.001411  [32000/60000]\n",
      "loss: 0.002349  [35200/60000]\n",
      "loss: 0.003499  [38400/60000]\n",
      "loss: 0.017847  [41600/60000]\n",
      "loss: 0.010744  [44800/60000]\n",
      "loss: 0.052188  [48000/60000]\n",
      "loss: 0.016572  [51200/60000]\n",
      "loss: 0.002989  [54400/60000]\n",
      "loss: 0.003677  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.038638 \n",
      "\n",
      "Epoch:  7\n",
      "--------------\n",
      "loss: 0.011574  [    0/60000]\n",
      "loss: 0.010880  [ 3200/60000]\n",
      "loss: 0.005641  [ 6400/60000]\n",
      "loss: 0.001201  [ 9600/60000]\n",
      "loss: 0.010078  [12800/60000]\n",
      "loss: 0.007914  [16000/60000]\n",
      "loss: 0.008927  [19200/60000]\n",
      "loss: 0.000220  [22400/60000]\n",
      "loss: 0.016384  [25600/60000]\n",
      "loss: 0.041372  [28800/60000]\n",
      "loss: 0.020165  [32000/60000]\n",
      "loss: 0.054525  [35200/60000]\n",
      "loss: 0.003362  [38400/60000]\n",
      "loss: 0.009879  [41600/60000]\n",
      "loss: 0.051480  [44800/60000]\n",
      "loss: 0.002605  [48000/60000]\n",
      "loss: 0.094519  [51200/60000]\n",
      "loss: 0.000711  [54400/60000]\n",
      "loss: 0.018805  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.035797 \n",
      "\n",
      "Epoch:  8\n",
      "--------------\n",
      "loss: 0.021005  [    0/60000]\n",
      "loss: 0.016692  [ 3200/60000]\n",
      "loss: 0.000864  [ 6400/60000]\n",
      "loss: 0.011140  [ 9600/60000]\n",
      "loss: 0.000594  [12800/60000]\n",
      "loss: 0.002524  [16000/60000]\n",
      "loss: 0.061847  [19200/60000]\n",
      "loss: 0.000676  [22400/60000]\n",
      "loss: 0.004925  [25600/60000]\n",
      "loss: 0.004954  [28800/60000]\n",
      "loss: 0.005294  [32000/60000]\n",
      "loss: 0.003474  [35200/60000]\n",
      "loss: 0.003903  [38400/60000]\n",
      "loss: 0.004926  [41600/60000]\n",
      "loss: 0.015333  [44800/60000]\n",
      "loss: 0.025925  [48000/60000]\n",
      "loss: 0.000456  [51200/60000]\n",
      "loss: 0.000908  [54400/60000]\n",
      "loss: 0.007077  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.033113 \n",
      "\n",
      "Epoch:  9\n",
      "--------------\n",
      "loss: 0.000163  [    0/60000]\n",
      "loss: 0.050644  [ 3200/60000]\n",
      "loss: 0.000332  [ 6400/60000]\n",
      "loss: 0.004775  [ 9600/60000]\n",
      "loss: 0.004375  [12800/60000]\n",
      "loss: 0.006246  [16000/60000]\n",
      "loss: 0.002393  [19200/60000]\n",
      "loss: 0.004990  [22400/60000]\n",
      "loss: 0.005420  [25600/60000]\n",
      "loss: 0.007038  [28800/60000]\n",
      "loss: 0.002163  [32000/60000]\n",
      "loss: 0.001204  [35200/60000]\n",
      "loss: 0.012859  [38400/60000]\n",
      "loss: 0.006237  [41600/60000]\n",
      "loss: 0.042925  [44800/60000]\n",
      "loss: 0.017157  [48000/60000]\n",
      "loss: 0.002306  [51200/60000]\n",
      "loss: 0.006890  [54400/60000]\n",
      "loss: 0.002487  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.030729 \n",
      "\n",
      "Epoch:  10\n",
      "--------------\n",
      "loss: 0.007850  [    0/60000]\n",
      "loss: 0.004884  [ 3200/60000]\n",
      "loss: 0.001828  [ 6400/60000]\n",
      "loss: 0.055507  [ 9600/60000]\n",
      "loss: 0.007009  [12800/60000]\n",
      "loss: 0.009378  [16000/60000]\n",
      "loss: 0.000169  [19200/60000]\n",
      "loss: 0.013232  [22400/60000]\n",
      "loss: 0.002076  [25600/60000]\n",
      "loss: 0.009195  [28800/60000]\n",
      "loss: 0.015852  [32000/60000]\n",
      "loss: 0.001576  [35200/60000]\n",
      "loss: 0.028145  [38400/60000]\n",
      "loss: 0.003097  [41600/60000]\n",
      "loss: 0.241236  [44800/60000]\n",
      "loss: 0.010452  [48000/60000]\n",
      "loss: 0.001105  [51200/60000]\n",
      "loss: 0.004329  [54400/60000]\n",
      "loss: 0.006681  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.034628 \n",
      "\n",
      "Epoch:  11\n",
      "--------------\n",
      "loss: 0.001255  [    0/60000]\n",
      "loss: 0.004982  [ 3200/60000]\n",
      "loss: 0.001482  [ 6400/60000]\n",
      "loss: 0.004341  [ 9600/60000]\n",
      "loss: 0.005569  [12800/60000]\n",
      "loss: 0.001328  [16000/60000]\n",
      "loss: 0.010215  [19200/60000]\n",
      "loss: 0.032645  [22400/60000]\n",
      "loss: 0.001322  [25600/60000]\n",
      "loss: 0.474233  [28800/60000]\n",
      "loss: 0.004146  [32000/60000]\n",
      "loss: 0.000926  [35200/60000]\n",
      "loss: 0.012004  [38400/60000]\n",
      "loss: 0.000717  [41600/60000]\n",
      "loss: 0.001088  [44800/60000]\n",
      "loss: 0.000264  [48000/60000]\n",
      "loss: 0.035391  [51200/60000]\n",
      "loss: 0.014047  [54400/60000]\n",
      "loss: 0.000123  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.034387 \n",
      "\n",
      "Epoch:  12\n",
      "--------------\n",
      "loss: 0.014665  [    0/60000]\n",
      "loss: 0.000738  [ 3200/60000]\n",
      "loss: 0.033676  [ 6400/60000]\n",
      "loss: 0.000600  [ 9600/60000]\n",
      "loss: 0.014097  [12800/60000]\n",
      "loss: 0.000215  [16000/60000]\n",
      "loss: 0.001809  [19200/60000]\n",
      "loss: 0.007941  [22400/60000]\n",
      "loss: 0.001920  [25600/60000]\n",
      "loss: 0.006988  [28800/60000]\n",
      "loss: 0.038126  [32000/60000]\n",
      "loss: 0.001159  [35200/60000]\n",
      "loss: 0.000187  [38400/60000]\n",
      "loss: 0.007852  [41600/60000]\n",
      "loss: 0.002167  [44800/60000]\n",
      "loss: 0.000388  [48000/60000]\n",
      "loss: 0.037711  [51200/60000]\n",
      "loss: 0.010100  [54400/60000]\n",
      "loss: 0.008173  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.033712 \n",
      "\n",
      "Epoch:  13\n",
      "--------------\n",
      "loss: 0.002913  [    0/60000]\n",
      "loss: 0.010181  [ 3200/60000]\n",
      "loss: 0.001229  [ 6400/60000]\n",
      "loss: 0.001813  [ 9600/60000]\n",
      "loss: 0.005988  [12800/60000]\n",
      "loss: 0.002760  [16000/60000]\n",
      "loss: 0.004939  [19200/60000]\n",
      "loss: 0.005097  [22400/60000]\n",
      "loss: 0.024037  [25600/60000]\n",
      "loss: 0.003261  [28800/60000]\n",
      "loss: 0.001063  [32000/60000]\n",
      "loss: 0.001623  [35200/60000]\n",
      "loss: 0.011878  [38400/60000]\n",
      "loss: 0.003269  [41600/60000]\n",
      "loss: 0.001993  [44800/60000]\n",
      "loss: 0.001075  [48000/60000]\n",
      "loss: 0.003772  [51200/60000]\n",
      "loss: 0.001194  [54400/60000]\n",
      "loss: 0.002259  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.037406 \n",
      "\n",
      "Epoch:  14\n",
      "--------------\n",
      "loss: 0.010255  [    0/60000]\n",
      "loss: 0.000171  [ 3200/60000]\n",
      "loss: 0.002119  [ 6400/60000]\n",
      "loss: 0.002706  [ 9600/60000]\n",
      "loss: 0.012133  [12800/60000]\n",
      "loss: 0.002118  [16000/60000]\n",
      "loss: 0.002390  [19200/60000]\n",
      "loss: 0.000914  [22400/60000]\n",
      "loss: 0.000566  [25600/60000]\n",
      "loss: 0.001308  [28800/60000]\n",
      "loss: 0.000339  [32000/60000]\n",
      "loss: 0.000200  [35200/60000]\n",
      "loss: 0.007182  [38400/60000]\n",
      "loss: 0.009111  [41600/60000]\n",
      "loss: 0.000034  [44800/60000]\n",
      "loss: 0.010904  [48000/60000]\n",
      "loss: 0.001107  [51200/60000]\n",
      "loss: 0.012481  [54400/60000]\n",
      "loss: 0.000104  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.034347 \n",
      "\n",
      "Epoch:  15\n",
      "--------------\n",
      "loss: 0.002604  [    0/60000]\n",
      "loss: 0.000756  [ 3200/60000]\n",
      "loss: 0.000180  [ 6400/60000]\n",
      "loss: 0.001204  [ 9600/60000]\n",
      "loss: 0.002818  [12800/60000]\n",
      "loss: 0.002807  [16000/60000]\n",
      "loss: 0.000517  [19200/60000]\n",
      "loss: 0.003089  [22400/60000]\n",
      "loss: 0.000368  [25600/60000]\n",
      "loss: 0.018476  [28800/60000]\n",
      "loss: 0.004499  [32000/60000]\n",
      "loss: 0.049230  [35200/60000]\n",
      "loss: 0.017829  [38400/60000]\n",
      "loss: 0.001969  [41600/60000]\n",
      "loss: 0.001015  [44800/60000]\n",
      "loss: 0.008091  [48000/60000]\n",
      "loss: 0.000503  [51200/60000]\n",
      "loss: 0.079681  [54400/60000]\n",
      "loss: 0.002128  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.033848 \n",
      "\n",
      "Epoch:  16\n",
      "--------------\n",
      "loss: 0.018580  [    0/60000]\n",
      "loss: 0.002329  [ 3200/60000]\n",
      "loss: 0.000673  [ 6400/60000]\n",
      "loss: 0.005632  [ 9600/60000]\n",
      "loss: 0.001122  [12800/60000]\n",
      "loss: 0.000409  [16000/60000]\n",
      "loss: 0.000684  [19200/60000]\n",
      "loss: 0.001030  [22400/60000]\n",
      "loss: 0.004359  [25600/60000]\n",
      "loss: 0.007165  [28800/60000]\n",
      "loss: 0.001270  [32000/60000]\n",
      "loss: 0.001753  [35200/60000]\n",
      "loss: 0.013516  [38400/60000]\n",
      "loss: 0.000234  [41600/60000]\n",
      "loss: 0.001054  [44800/60000]\n",
      "loss: 0.002368  [48000/60000]\n",
      "loss: 0.000727  [51200/60000]\n",
      "loss: 0.000396  [54400/60000]\n",
      "loss: 0.000532  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.032914 \n",
      "\n",
      "Epoch:  17\n",
      "--------------\n",
      "loss: 0.000894  [    0/60000]\n",
      "loss: 0.012971  [ 3200/60000]\n",
      "loss: 0.000148  [ 6400/60000]\n",
      "loss: 0.000214  [ 9600/60000]\n",
      "loss: 0.000022  [12800/60000]\n",
      "loss: 0.002528  [16000/60000]\n",
      "loss: 0.008849  [19200/60000]\n",
      "loss: 0.000417  [22400/60000]\n",
      "loss: 0.000599  [25600/60000]\n",
      "loss: 0.003711  [28800/60000]\n",
      "loss: 0.001170  [32000/60000]\n",
      "loss: 0.002392  [35200/60000]\n",
      "loss: 0.007187  [38400/60000]\n",
      "loss: 0.003734  [41600/60000]\n",
      "loss: 0.000665  [44800/60000]\n",
      "loss: 0.000311  [48000/60000]\n",
      "loss: 0.005655  [51200/60000]\n",
      "loss: 0.000361  [54400/60000]\n",
      "loss: 0.001085  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.038573 \n",
      "\n",
      "Epoch:  18\n",
      "--------------\n",
      "loss: 0.005404  [    0/60000]\n",
      "loss: 0.002226  [ 3200/60000]\n",
      "loss: 0.000035  [ 6400/60000]\n",
      "loss: 0.000071  [ 9600/60000]\n",
      "loss: 0.000506  [12800/60000]\n",
      "loss: 0.000178  [16000/60000]\n",
      "loss: 0.000377  [19200/60000]\n",
      "loss: 0.000088  [22400/60000]\n",
      "loss: 0.000501  [25600/60000]\n",
      "loss: 0.001437  [28800/60000]\n",
      "loss: 0.008123  [32000/60000]\n",
      "loss: 0.000476  [35200/60000]\n",
      "loss: 0.000286  [38400/60000]\n",
      "loss: 0.012924  [41600/60000]\n",
      "loss: 0.000167  [44800/60000]\n",
      "loss: 0.000170  [48000/60000]\n",
      "loss: 0.007430  [51200/60000]\n",
      "loss: 0.001021  [54400/60000]\n",
      "loss: 0.001266  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.035805 \n",
      "\n",
      "Epoch:  19\n",
      "--------------\n",
      "loss: 0.000241  [    0/60000]\n",
      "loss: 0.000198  [ 3200/60000]\n",
      "loss: 0.003200  [ 6400/60000]\n",
      "loss: 0.008961  [ 9600/60000]\n",
      "loss: 0.000685  [12800/60000]\n",
      "loss: 0.004220  [16000/60000]\n",
      "loss: 0.000313  [19200/60000]\n",
      "loss: 0.000382  [22400/60000]\n",
      "loss: 0.002716  [25600/60000]\n",
      "loss: 0.003687  [28800/60000]\n",
      "loss: 0.022862  [32000/60000]\n",
      "loss: 0.000767  [35200/60000]\n",
      "loss: 0.003670  [38400/60000]\n",
      "loss: 0.000109  [41600/60000]\n",
      "loss: 0.001465  [44800/60000]\n",
      "loss: 0.004236  [48000/60000]\n",
      "loss: 0.002232  [51200/60000]\n",
      "loss: 0.001374  [54400/60000]\n",
      "loss: 0.039334  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.033900 \n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print(\"Epoch: \", epoch)\n",
    "    print(\"--------------\") \n",
    "\n",
    "    running_loss = 0.0\n",
    "    size = len(trainloader.dataset)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cmodel4(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(inputs)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "    size = len(testloader.dataset)\n",
    "    num_batches = len(testloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in testloader:\n",
    "            #X = X.to(device)\n",
    "            #y = y.to(device)\n",
    "            pred = cmodel4(X)\n",
    "            test_loss += criterion(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = cmodel4(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eef1e96883d221b10cc8565d34f43936e0ec43919084d9673b5622bba3d2f1aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
